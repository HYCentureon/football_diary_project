{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. RNN을 활용한 일기 생성 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import tensorflow.contrib.rnn as rnn\n",
    "import tensorflow.contrib.layers as layers\n",
    "from text_loader import TextLoader "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 데이터 불러오기\n",
    "\n",
    "num_layers  = 3\n",
    "hidden_size = 512\n",
    "batch_size  = 1\n",
    "max_length  = 1000\n",
    "\n",
    "loader = TextLoader(\"data/football_diary_normalization.txt\")\n",
    "vocab_size = len(loader.vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = tf.placeholder(tf.int32, [None, None])\n",
    "x_one_hot = tf.one_hot(X, vocab_size)\n",
    "\n",
    "cells = [rnn.BasicLSTMCell(hidden_size) for _ in range(num_layers)]\n",
    "cells = rnn.MultiRNNCell(cells, state_is_tuple=True)\n",
    "\n",
    "initial_state = cells.zero_state(batch_size, tf.float32)\n",
    "outputs, states = tf.nn.dynamic_rnn(cells, x_one_hot, \n",
    "                                    initial_state=initial_state, dtype=tf.float32)\n",
    "\n",
    "outputs = tf.reshape(outputs, [-1, hidden_size])\n",
    "logits = layers.fully_connected(outputs, vocab_size,\n",
    "                                activation_fn=None)\n",
    "y_softmax = tf.nn.softmax(logits)\n",
    "pred = tf.argmax(y_softmax, axis=1)\n",
    "pred = tf.reshape(pred, [batch_size, -1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start with: 역전승을 거두었다\n",
      "INFO:tensorflow:Restoring parameters from char-rnn_116000\n",
      "역전승을 거두었다 키미에서 남았다. 호주는 패스를 잘하는데……. 엄마, 아빠께서는 이란 편을 해 주었다. 내 동생과 나는 호주를 응원하는데……. 그런데 이란이 한골을 허용하였다. 이란이 공격을 더 해왔다. 그래서 2골이 허용되었다. 시간은 좀 남았다. 2-2로 비길 경우 이란이 나간다고 하는데……. 시간이 많이 지나갔다. 주심이 호루라기를 불었다. 이란이 본선 티켓을 탄 것이다. 마지막 티켓을 쥔 이란. 참 좋겠다.\n",
      "일요일에 서정원 선수 아저씨의 꿈을 꾸었다. 지난 번에는 또 최용수 선수 아저씨의 꿈을 꾸었었다. 하지만 지금은 서정원 선수 아저씨의 꿈을 말하겠다. 서정원 선수 아저씨가 우리 피아노 학원에 다니는데 아이들이 서정원 선수 아저씨가 수고했다고 편지를 주었다. 나도 편지를 주었다. 하루는 내가 피아노 학원에 갔다. 그런데 서정원 선수 아저씨가 원장 선생님께 레슨을 받고 있었다. 서정원 선수 아저씨가 “현아야!” 라고 불렀다. 그런데 일어나보니 엄마께서 부르는 소리였다. ‘이게 뭔 꿈인다냐?’ 꿈 꿀 동안에 참 재미있었다.\n",
      "1월 25일 일요일 바로 오늘 방콕에서 한국 국가 선수 아저씨들이 덴마크와 축구를 한다. 그런데 하는 것을 보여주지 않는다. 그 이유는 경제가 어렵기 때문이다. 스포츠 뉴스 아나운서가 지금은 한국이 덴마크에게 1점을 주었다고 말하였다. 중계는 안하지만 한국이 2대1이라도 이겼으면 좋겠다. 중계를 했으면 엄청 좋겠었는데……. IMF시대를 빨리 극복을 하여서 축구중계를 볼 수 있게 했으면 좋겠다. 또 이유가 있다. 영국의 방송국에서 독점중계를 하면서 축구대회의 중계방송하는 비용을 한국의 방송국에 너무 많이 내라고 돈을(달러$) 요구했기 때문에 우리나라 방송국 취소를 했다. 아마도 IMF 때문에 그런 것 같다. 다음에 IMF를 극복하서 꼭 축구중계를 했으면 하늘에 날아갈 것 같은 기분일 것이다.\n",
      "오늘 아침 덴마크 2-1 한국 우리가 졌다.\n",
      "요번 설날 전에 한 이집트 대 한국을 못보았다. 스포츠 뉴스도 못 들었다. 설날에 집에 올 때 차 안에서 스포츠 뉴스\n"
     ]
    }
   ],
   "source": [
    "# 문장 하나씩을 입력값으로 넣고, 일기 생성 파악\n",
    "\n",
    "sentence = list(\"역전승을 거두었다\")\n",
    "\n",
    "print(\"Start with:\", \"\".join(sentence))\n",
    "sentence = [loader.vocab[word] for word in sentence]\n",
    "\n",
    "saver = tf.train.Saver()\n",
    "sess_config = tf.ConfigProto(gpu_options=tf.GPUOptions(allow_growth=True))\n",
    "with tf.Session(config=sess_config) as sess:\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    saver.restore(sess, \"char-rnn_116000\")\n",
    "    \n",
    "    # 매 이터레이션마다 글자 하나씩 생성\n",
    "    pred_char, state = sess.run([pred, states], feed_dict={X:[sentence[:]]})\n",
    "    for i in range(1000):\n",
    "        pred_char, state = sess.run([pred, states], \n",
    "            feed_dict={X:[[sentence[-1]]], initial_state: state}) # 이전 스텝에 갖고 있는 state 값을 다음 스텝에 넣어줌\n",
    "        sentence.append(pred_char[0][-1])\n",
    "        \n",
    "sentence = [loader.words[char] for char in sentence]\n",
    "print(\"\".join(sentence))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### => RNN을 통한 일기 생성 분석"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> * 상대적으로 적은 양의 데이터로 인해 짧은 시간에도 불구하고 상대적으로 빅데이터들보다는 많은 학습을 할 수 있었다. \n",
    "> * 내용에 있어서는 문맥은 맞고 내용도 맞으나 전체적인 맥락들은 아직 맞지 않는다는 것이 한계점이라고 말할 수 있다. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "        "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
